---
title: 'ML на клиенте: Часть 2. Продвинутое распознавание белочек.'
date: '2022-06-20T17:22:25.789Z'
tags: ['ML/DL']
slug: 'even-better-squirrel-detector'
published: true
description: 'Как можно использовать ML/DL на фронте, что это вообще такое и где может пригодиться. Часть 2.'
image: '/images/sqMLDL.webp'
---

import { Image } from '../components/Image'
import { Details } from '../components/Details'
import { LayersModel } from '../components/LayersModel'
import { TenLayersModel } from '../components/TenLayersModel'

import modelSummary from './assets/modelSummary.png'
import squirrelNT from './assets/squirrelNT.png'
import useless1000Classes from './assets/useless1000Classes.png'
import fatVsSlim from './assets/fatVsSlim.png'

## Нужно больше цифровых белочек!

[В первой части](/blog/how-to-blur-a-squirrel) мы с вами отлично поработали: перестали бояться математики, научились узнавать белочек и заглянули внутрь классифицирующей нейросети.
Давайте двигаться дальше! Используем наши знания чтобы узнавать белочек еще лучше!
Мы снова будем использовать [tensorflowjs](https://www.tensorflow.org/js) и [tensorflow](https://www.tensorflow.org). Поехали :)

## Что можно улучшить?

В прошлом разделе мы взяли уже готовую модель, обученную на ImageNet. Она умеет распознавать множество классов, но это немного не то что нам было нужно.
Мы хотели отличать белочек от прочей живности. При этом распознавать шторки для ванной или пожарные гидранты нам не обязательно.
Вот что выдавала предыдущая модель:

<LayersModel />

Как видите результаты не очень. Давайте попробуем это улучшить.

Сначала сформулируем задачу:

<Details title="Кстати о постановке задач">
  Я искренне считаю, что перед тем как начинать пилить любую фичу надо потратить
  некоторое время чтобы понять что именно от нас требуется. И только после этого
  начинать собственно пилить. Это сэкономит время, ресурсы и, иногда, даже
  нервы.
</Details>

Итак мы хотим распознавать белочек. На всякий случай добавим в нашу модель еще возможность
распознавать котиков, собачек, лошадок... ну вы поняли:)

```ts
const classes = [
  'dog',
  'horse',
  'elephant',
  'butterfly',
  'chicken',
  'cat',
  'cow',
  'sheep',
  'spider',
  'squirrel',
]
```

Заглянем внутрь текущей модели:

<Image {...useless1000Classes} />

Тут все хорошо, кроме последнего слоя. Все что нам нужно сделать, это оторвать у модели хвост и приделать новый.
Как я уже упоминала, наша модель это граф. Мы можем перестраивать этот граф так, как нам нравится.
Эту технику можно использовать как на клиенте так и на сервере. API, правда, будет немного отличаться.

Вот так мы соединяем слои в tensorflowjs:

```ts
const inputs = oldModel.layers[0].input
const output = oldModel.layers[3].output
const newLayer = // как-то определили новый слой
const outputs = newLayer.apply(output)
newModel = tf.model({ inputs, outputs })
```

A вот как если используем питонячью реализацию:

```python
inputs = old_model.input
out = old_model(inputs)
new_layer = # как-то определили слой
outputs = new_layer(out)
new_model = keras.Model(inputs=inputs, outputs = outputs)
```

Нам нужно заменить старый слой `Dense(1000)` на новый `Dense(10)`. Где 10 - это количество элементов в `classes`
Получившуюся модель нужно заново потренировать на подходящем датасете, который должен состоять из картинок нужных нам классов.
Раздобыть такой можно, например, на kaggle.

Еще одна хорошая новость – нам не нужно обучать все слои новой модели. Достаточно просто потренировать наш новый хвост.

<Details title="Не обязательно тренировать только один слой">
  Мы можем потренировать и остальные слои, если нам захочется. Это потенциально
  может добавить нашей модельке точности. Для этого нужно "разморозить" все
  нужные слои. Обычно размораживают несколько последних.
</Details>

Для этого нужно "заморозить" все предыдущие слои. То что мы сейчас проделываем используется
очень часто и называется transfer learning. Есть куча гайдов о том как это правильно
готовить. Вот, [например от tensorflow](https://www.tensorflow.org/tutorials/images/transfer_learning)

Примерно так будет выглядеть ваш финальный код на питончике.

```python
headless_model.trainable = False
outputs = headless_model(headless_model.input, training=False)
dense_out = layers.Dense(10, activation="softmax")(x)
classifier = keras.Model(inputs=headless_model.input, outputs = dense_out)
```

Тренировка не займет много времени. На моем маке (с M1 :) ) мне понадобилось примерно две минуты чтобы дообучить новую модель.

Теперь нужно сконвертировать обученное и скормить это браузерному tensorflow.
Если мы используем tensorflow для обучения и если мы не пишем никакого экзотического кода, с конвертацией проблем не возникнет.

<Details title="Так у меня весь код экзотический!111">
  У меня тоже, хе-хе. Я планирую чуть более подробно рассказать о конвертации в
  следующих частях. Сейчас предлагаю использовать вот такое правило: Используем
  только операции из [этого
  списка](https://github.com/tensorflow/tfjs/blob/master/tfjs-converter/docs/supported_ops.md)
  По возможности никаких кастомных слоев и никаких кастомных моделей.
</Details>

Сохраняем модель в формате [h5](https://www.tensorflow.org/guide/keras/save_and_serialize#keras_h5_format), потом конвертируете при помощи [tensofrlowjs_converter](https://github.com/tensorflow/tfjs/tree/master/tfjs-converter)

```
!tensorflowjs_converter \
    --input_format=keras \
    --output_format=tfjs_layers_model \
    {model_in_path} \
    {model_out_path}
```

Как загрузить модель мы уже знаем

```ts
await tf.loadLayersModel(modelUrl)
```

Давайте загрузим сразу обе модели: старую с последним слоем на 1000 классов и новую. И сравним что получилось:

```ts
oldModel.summary()
newModel.summary()
```

<Image {...fatVsSlim} />

Вторая модель выглядит странно. Куда подевались все наши слои? Из-за того что мы немножко перетрясли граф, весь MobileNet теперь запрятан внутрь `model_4`.
Обратите внимание на последний слой - теперь там 10 классов. Ровно то что мы хотели.

У второй модели меньше `trainable parameters`. Разберемся почему:

Обратите внимание на последний слой – `Dense`. Все элементы слоев такого типа соединены со всеми элементами предыдущих.
Как видно из картинки на предыдущем слое у нас `prevOutput = 1280` параметров. Нам надо соединить их с `lastOutput = 1000` параметрами на новом слое.
Плюс нам надо еще добавить вектор `bias` чья размерность совпадает с размерностью последнего слоя `lastOutput`.
Проверим что это действительно так:

```ts
const logModelInfo = (model: LayersModel) => {
  model.summary()
  const totalParams = model.countParams()
  const lastLayer = model.layers.slice(-1)[0]
  const prevLayer = model.layers.slice(-2)[0]

  const lastOutput = lastLayer.outputShape[1]
  const prevOutput = prevLayer.outputShape[1]
  console.log('totalParams = ', totalParams)
  console.log(
    `on the last layer = ${lastOutput} * ${prevOutput} + ${lastOutput}`
  )
}
```

В результате у нас стало на `(1280 * 1000) + 1000 - (1280 * 10) - 10 = 2560` параметров меньше. И наша модель похудела на `5.2Mb`

C точностью теперь все тоже хорошо :)

<TenLayersModel />

## Итеративные оптимизации наше все

У нас получилось разобраться в transfer learning и уменьшить размер нашей модели. Но это только первые шаги :)
Мы используем не самый эффективный формат `layersModel` и пока не понимаем как все работает под капотом.
В следующих постах нас ждут новые оптимизации и генераторы белочек :)
