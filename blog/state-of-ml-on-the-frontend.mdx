---
title: 'А чего мльного у нас нынче на фронте?'
date: '2022-04-08T17:04:15.630Z'
tags: ['ML/DL']
slug: 'state-of-ml-on-the-frontend'
published: true
---

import Image from 'next/image'
import ImperativeSquirrel from '../components/imperativeSquirrel.tsx'
import LayersModel from '../components/LayersModel'

import tf from './assets/tf.png'
import SquirrelCoords from './assets/squirrelCoords.svg'
import Squirrel from './assets/squirrel.svg'
import pca from './assets/pca.png'
import modelSummary from './assets/modelSummary.png'

# Все что вам нужно знать о цифровых белочках

Поговорим о том как умножая и складывая матрицы получать крутые спецэффекты... А иногда и делать что-то полезное.
Начну с вымышленной истории :)

## Маленький фронтенд который боялся математики

Жил-был фронтенд-разработчик. Он не сразу стал заниматься фронтом. Сначала он закончил крутые курсы, научился в React и Redux.
Он устроился в крупную компанию, верстал там формочки и был счастлив.
Но однажды к нему пришел грустный техлид проекта.
Он рассказал как в их чудесном сервисе где можно подгружать видяшки с белочками стали появляться видяшки с котиками и что это совершенно недопустимо.
Нужен какой-то способ понять что на видео не белочка, а котик и предупредить пользователя об этой ужасной ошибке!

Фронтенд пошел гуглить. К сожалению, по запросу "js отличить белочку от котика" ничего толкового не нашлось.
Но вот на stackoverflow ему посоветовали использовать очень крутой фреймворк для распознавания белочек. Tensorflow называется
Фронтенд пошел читать документацию ...
Сначала ему почему-то рекомандовали установить питон (а как известно некоторые фронтенды боятся змей),
Потом фронтенд заглянул в следующий раздел и увидел вот такое:

<Image {...tf} />

Тензоры? Дата сеты? Слайсы? Фронтенд загрустил и решил делегировать задачу департаменту машинного обучения. Правда потом он вспомнил что такого департамента в их компании нет :)

## A собственно чего тут бояться?

Почему подобные задачи кажутся сложными? Потому что иногда мы боимся математики. Этот страх появляется еще в школе и развивается превращаясь в уверенность "вот никогда-никогда никаких логарифмов и интегралов".
Боимся мы зря. Математика значительно упрощают фронтожизнь.

Большинтсво читателей наверняка когда - нибудь пользовались CSS
Наверное приходилось писать вот такое:

```css
.squirrel {
  transform: translateX(100px);
}
```

А некоторым и вот такое:

```css
.squirrel {
  transform: skewX(1);
}
```

А иногда и вот такое

```css
.squirrel {
  transform: rotate(90deg);
}
```

Для всех случаев можно написать одну общую трансформацию :

```css
.squirrel {
  transform: matrix3d(0, -1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, -100, 0, 0, 1);
}
```

Прикольно же: не надо думать, надо просто подставить нужные циферки в нужное место

Пожалуй надо уточнить что matrix это двумерный массив.

```ts
;[
  [0, -1, 0, 0],
  [1, 0, 0, 0],
  [0, 0, 1, 0],
  [-100, 0, 0, 1],
]
```

И раз уж мы заговорили о массивах... Массивы могут быть многомерными.
В контексте ML мы называем многомерные массивы с элементами одного типа тензорами.
Это не вполне корректно, но все что нам нужно знать это:

1. Тензор можно представить как многомерный массив
2. У тензора есть ранг и размерность.
   Ранг это сколько индексов нам понадобится чтобы достать элемент из тензора.
   Размерность это количество элементов по каждой из осей.
   Наша матрица из примера это тензор ранга 2 размерностью `3 x 3`.
3. Как правило тензоры описывают преобразования между элементами нашего пространства.

Посмотрим как это работает на белочках: Для каждого беличьего пискеля с координатами `x y` мы можем получить новые координаты умножив `x y` на матрицу из снипета выше.

<SquirrelCoords className="img" />

Окей. С тензорами разобрались и математики больше не боимся. Поехали дальше.

## Декларативно или императивно?

Есть два стиля написания кода: декларативный и императивный

В первом случае у нас есть некая машинерия которая позволяет нам формулировать проблемы на человеческом языке
и описывать решения этих проблем в виде "я хочу чтобы..."

При этом, используя декларативный подход мы не особо заморачиваемся на детали реализации. Мы говорим _что_ мы хотим. Нам не важно _как_ мы получим результат.
А вот используя императивный мы сосредотачиваемся на деталях реализации.

Давайте сделаем что-нибудь императивное на старом-добром джаваскрипте.
Напишем функцию которая умеет складывать и перемножать циферки.

Смотрите как имперетивно:

```ts
const createValueGetter = (a, b) => x => a * x + b
const getValue = createValueGetter(2, 5)
console.log([1, 2].map(getValue)) // [7, 9]
```

## ML за 5 минут:

Мы можем действовать ровно наоборот: Создаем модель. Говорим ей что у нас есть (inputs) и что мы хотим получить (realOutputs)
Дальше мы как-то тренируем нашу модель чтобы она умела выдавать нужные результат.
Смотрите как декларативно:

```ts
const inputs = [1, 2, 3, 4]
const realOutputs = [7, 9, 11, 13] // values.map(getOutput)

// ... some boring implementation of a network

const learnedParams = doTrain()
const result = layer(inputs, ...learnedParams)

console.log(result) // [6.952457161700541, 8.9797075504127, 11.00695793912486, 13.034208327837018]
```

На модель можно смотреть как черный ящик. Мы закидываем в него парамерты и ожидаемый результат.
В процессе обучения наш черный ящик изменяет свою структуру так, что на выходе всегда будет получаться то что нам нужно.

И тут у нас сразу же возникает пачка вопросов:

## Что там внутри ящика?

Для этого давайте посмотрим на полную реализацию примера выше

```ts
// императивненько
const createValueGetter = (a, b) => x => a * x + b
const getOutput = createValueGetter(2, 5)
console.log([1, 2].map(getOutput)) // [7, 9]

const inputs = [1, 2, 3, 4]

const realOutputs = [7, 9, 11, 13] // values.map(getOutput)
// const getValueWithML =  ??

// готовим декларативность :)

const trainStep = (a, b, inputs, realOutputs, step) => {
  const outputs = layer(inputs, a, b)
  const gradL = outputs.map((y, index) => y - realOutputs[index])

  const gradA = gradL.map((gr, i) => gr * outputs[i]).reduce((a, b) => a + b, 0)
  const gradB = gradL.reduce((a, b) => a + b, 0)

  return [a - gradA * step, b - gradB * step]
}

// and here is our declarative version

// задаем начальные параметры
const learningRate = 0.001
const numberOfSteps = 10000
const initialParams = [Math.random(), Math.random()]

// задаем нашу "архитектуру"
const layer = (inputs: number[], ...params: [number, number]): number[] =>
  inputs.map(x => params[0] * x + params[1])

// задаем как сравнивать результаты
const loss = (outputs: number[], realOutputs: number[]): number =>
  outputs
    .map((y, index) => Math.pow(y - realOutputs[index], 2))
    .reduce((a, b) => a + b, 0)

// 🏋️
const doTrain = (): [number, number] =>
  [...Array(numberOfSteps)].reduce((currentParams: [number, number]) => {
    console.log(
      ...currentParams,
      loss(layer(inputs, ...currentParams), realOutputs)
    )
    return trainStep(...currentParams, inputs, realOutputs, learningRate)
  }, initialParams)

const learnedParams = doTrain()

const result = layer(inputs, ...learnedParams)
console.log(result) // [6.952457161700541, 8.9797075504127, 11.00695793912486, 13.034208327837018]
```

TLDR:

1. Мы определяем "архитектуру ящика". Это набор функций через которые мы будем прогонять наши входные данные.
   В нашем примере это

```ts
const layer = (inputs: number[], a: number, b: number): number[] =>
  inputs.map(x => a * x + b)
```

Я не просто так назвала эту функцию слоем (layer).

Наша чОрный ящик это вообще-то маленькая нейросеть :)  
Давайте пока считать что нейросеть композиция функций-слоев:

```ts
const networkOutput =
  // ... layer 100
  layer3(layer2(layer1(inputs)))
```

У каждого слоя есть свои парамерты. Наша задача их подобрать.

// TODO: add picture

Важно заметить, что мы использовали суперпремитивную функцию для нашего слоя. Реальные слои чаще сложнее

## Как подобрать параметры?

Во-первых нам нужно выдать сеточке метрику, которая будет показывать насколько то она выдает отличается от того что мы хотим получить.
Эта метрика называется функцией потерь (loss fucntion).

В нашем случае это

```ts
const loss = (outputs: number[], realOutputs: number[]): number =>
  outputs
    .map((y, index) => Math.pow(y - realOutputs[index], 2))
    .reduce((a, b) => a + b, 0)
```

Кстати, это что-то похожее на [MSE](https://en.wikipedia.org/wiki/Mean_squared_error)

Сначала мы прогоняем наши данные через сеть и считаем результат с текущими параметрами. Затем мы вычисляем функцию потерь и стараемся изменить параметры так, чтобы потери уменьшились.
Мы уже знаем из предыдущего раздела, что наша сеть это набор слоев: мы подаем значения на вход, получаем значения на выходе.
В процессе обучения мы вычисляем как сильно влияет изменение каждого параметра на выходные значения каждого слоя (помните в школе были такие производные. Вот это они. А если скомбинировать производные по каждому параметру в вектор, то получится вектор градиент)

Мы учитываем градиенты при изменении параметра. Ведь чем больше градиент тем сильнее соответствующий параметр влияет на результат.

Есть огромное количество ресурсов где про это рассказывают подробно, например [вот тут](https://www.youtube.com/watch?v=7sB052Pz0sQ&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI)

## И для каких случаев этот подбор будет успешным?

Есть прикольная теорема, называется [универсальная теорема аппроксимаци](https://web.archive.org/web/20151010204407/http://deeplearning.cs.cmu.edu/pdfs/Cybenko.pdf)
Она утверждает что используя определенный набор слоев мы с нужной точностью можем приближать любую непрерывную функцию.
Т.е если у нас есть какая-то зависимость между входными и выходными параметрами, мы как-то можем посчитать потери и функция которую мы для этого используем достаточно симпатичная
(простите меня, товарищи небезразличные к математике), то наша сеточка может научиться вести себя так же как эта зависимость.

## Это было просто. Давайте сделаем что-нибудь посложнее.

Как и в прошлый раз начнем с имеративного случая :)

Есть картинка белочки. Нужно ее заблюрить.
Я не буду приводить здесь код преобразования пикселей в `Uint8ClampedArray` и рисования красивостей на `canvas`
Посмотрим только на блюрющую математику

```ts
const kernel = [
  [1 / 16, 1 / 8, 1 / 16],
  [1 / 8, 1 / 4, 1 / 8],
  [1 / 16, 1 / 8, 1 / 16],
]

const convStep = (arr1: number[], kernel): number =>
  kernel.flat().reduce((acc, v, i) => acc + v * arr1[i], 0)

const convolve = (
  array: Uint8ClampedArray,
  kernel: number[][],
  w: number,
  h: number,
  stride = 1,
  chInImage = 4
): Uint8ClampedArray => {
  const result = new Uint8ClampedArray(w * h * chInImage).fill(255)
  const kh = kernel.length
  const kw = kernel[0].length

  for (let i = 0; i < w - kw; i += stride) {
    for (let j = 0; j < h - kh; j += stride) {
      for (let c = 0; c < chInImage; c++) {
        const arrToConsolve: number[] = []
        for (let k = 0; k < kw; k++) {
          for (let l = 0; l < kh; l++) {
            arrToConsolve.push(
              array[
                chInImage * w * j +
                  chInImage * i +
                  c +
                  chInImage * k +
                  chInImage * l * kw
              ]
            )
          }
        }

        const convStepResult = convStep(arrToConsolve, kernel)
        result[chInImage * w * j + chInImage * i + c] = convStepResult
      }
    }
  }

  return result
}

const blurredSquirrel = convolve(
  imagePixels,
  kernel,
  originalSquirrel.width,
  originalSquirrel.height
)
```

Мало того что мы заблюрили белочку мы еще и побили рекорд. 5! вложенных циклов `for`

<details>
  Кстати! Если вы попробуете использовать функцию выше на картинках большого
  размера ваш интерфейс будет лагать. Чинится очень просто – выносим нашу
  матетатику в отдельный [Web
  Worker](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API)
</details>

<ImperativeSquirrel />

Все очень императивно, правда же? У нас есть готовые числа (их еще называют ядром (и мы теперь знаем что это тензор :)). Мы берем эти числа и выполняем заранее известные преобразования.
Для блюра белочки мы использовали операцию [convolve](https://en.wikipedia.org/wiki/Convolution). Эта операция берет матрицу заданного размера, выбирает кусочек картинки такого же размаре и "сворачивает" их вместе.
Сворачиваем так: перемножаем все значения матрицы на значения соответствующих пикселей. А потом складываем все результаты.

Выбирая правильные ядра мы можем по-разному преобразовывать нашу картинку:

- детектировать грани разных направлений
- сглаживать и шарпить
- менять цвета, яркость и контраст

## Цифровые белки опасны!

Давайте посмотрим на другую белочку.

<Squirrel className="img" />

Вне зависимости от того какую задачу мы решаем, нам понадобится преставить белочку в виде циферок.
Первый делом мы просто превратим наше изображение в набор сырых пикселей.

Если размрер белочки `M * N (2388 x 1668)` и белочка черно-белая (мы используем только один канал), то нам понадобится матрица размером `2388 x 1668 x 1`.

Работать с такими большими объемами данных тяжело. Для примера с блюром, время заблюривания линейно зависит от `M x N`
Хорошие новости – нам не нужны все пиксели нашего изображения.
Вместо этого мы можем представить нашу белочку как-то иначе.

## Фичи

Если мы "расплющим" беличью матрицу, получится боооольшой массив длинной 3983184 (это примерно 3.8 Mb).
С другой стороны, если мы сохраним белочку в фромате SVG, мы получим всего 16Kb.
При этом мы можем смотреть на наше изображение как на набор геометрических примитивов. Простых: кружочки и квадратики которые в свою очередь формируют более сложные – беличий хвост.
Дальше мы можем как-нибудь закодировать наши геометрические примитивы и получить тензор с "фичами" которые можно использовать для решения нужной нам задачи.
Часть информации о белочке при этом потеряется, но при должной сноровке мы сможем восстановить белочку из этих фич.

Давайте попробуем это сделать, использовав [PCA](https://en.wikipedia.org/wiki/Principal_component_analysis)

Решаем следующую задачу: дан набор из 800 картинок и белочка. Сколько фич нам нужно чтобы уверенно отличать белочку от других картинок?
Использовав PCA мы уменьшаем разрешение нашей белочки до 340 (это примерно 0.33 КБ).

Вот так это выглядит. Слева - оригинал, справа - восстановленная из 340 фич белка

<Image {...pca} />

## Зачем мы занимаемся этими странными штуками?

Несколько причин:
Во-первых было бы прикольно скармливать нейросети "урезанных белочек". Рассуждения выше позволяют примерно представить насколько их можно урезать.
Во-вторых мы можем использовать идеи изложенные выше чтобы определять архитектуру нашей сети. Но пока оставим в покое разложение в займемся классификацией белок.

## Настало время решить ту неподъемную задачу и наконец-то отличить белку от кота!

Разумеется более общую задачу уже давно решили за нас. Вот этим и воспользуемся.
Готовых нейросеточек, умеющих решать эту задачу очень много. Мы возьмем ту что полегче - [MobileNet](https://github.com/tensorflow/tfjs-models/tree/master/mobilenet)

Первым делом нам нужно загрузить готовую модель. Для этого примера я буду использовать [tensorflowjs](https://www.tensorflow.org/js).
Пока нам не важно что это и как работает. Главное что может модельки грузить :)

```ts
const loadModel = async (): Promise<tf.LayersModel> => {
  const model = await tf.loadLayersModel(MODEL_URL)
  return model
}
```

Отлично! Моделька загружена. Теперь давайте посмотрим что там у нее внутри

```ts
model.summary()
```

<Image {...modelSummary} />

Ага! Слои присуствуют, параметры присуствуют и там еще наши старые добрые функции convolve есть.
Наша модель треноровалась по огромном дата-сете [ImageNet](https://en.wikipedia.org/wiki/ImageNet).
Она может предсказывать 1000 классов изображений, которые мы заботливо сложили в json. В нашем примере `IMAGENET_CLASSES` это как раз оно.

Чтобы запихнуть белку, кота или кого там нам еще захочется в модель, надо написать хелпер который после небольшого препроцессинга картинки выдаст нам нужные вероятности:

```ts
const MODEL_URL = '/models/mobilenet/model.json'
const PREPROCESS_DIVISOR = tf.scalar(255 / 2)
const MAX_PROB = 0.05
const WIDTH = 224
const HEIGHT = 224

const predict = async (input: tf.Tensor, model: tf.LayersModel) => {
  const preprocessedInput = tf.div(
    tf.sub(input.asType('float32'), PREPROCESS_DIVISOR),
    PREPROCESS_DIVISOR
  )
  const reshapedInput = preprocessedInput.reshape([
    -1,
    ...preprocessedInput.shape,
  ])
  return model.predict(reshapedInput)
}

const getProbs = async (
  img: HTMLImageElement,
  model: tf.LayersModel
): Promise<Predictions> => {
  // превращаем картинку в тензор
  const tensor = tf.browser.fromPixels(img)
  // предсказываем
  const result = await predict(tensor, model)
  const predictedClasses = tf.tidy(() => {
    const data = (result as tf.Tensor).dataSync()
    return data
      .reduce((acc, val, idx) => {
        // нас интересуют только большие вероятности
        if (val > MAX_PROB) {
          return [
            ...acc,
            {
              prob: val,
              // модель натренирована на IMAGE_NET, там 1000 классов
              cl: IMAGENET_CLASSES[idx][1],
            },
          ]
        }

        return acc
      }, [])
      .sort((a, b) => (a.prob > b.prob ? -1 : 1))
  })

  return predictedClasses
}
```

И вот что получается

<LayersModel />

Обратили внимание что мы сплющили белку? Дело в том, что та разновидность MobileNet которую мы используем кушает картинки размером 224 x 224. Поэтому нам нужно было отресайзить животных с искажением их пропорций.

## А что там за слои такие?

Давайте дальше разбираться в нашей модели. Как вообще она учится и что делает?
Мы можем на это посмотреть :)

## TODO: продолжение следует :)

## TODO а что это вообще такое?

Мой коллега утверждает что tf это как функциональное программирование :)

## TODO Tensorflow tools and sources

[tf-vis](https://js.tensorflow.org/api_vis/latest/)
[XNNPACK](https://github.com/google/XNNPACK)

## Tensorflow производительность

Иногда рекомендуют использовать spritesheets для тренировки CNN. Но вспомните в каком мы году!
Все уже давно используют http/2 а некоторые даже http/3. Новые версии протоколов поддерживают мультиплексирование.
Так что никакие спрайты вам не нужны

А вот то о чем не стоит забывать это пожираемая память. Есть специальная функция tf.tidy, которая позволяет вычищать промежуточные тензоры из памяти

Tensorflow очень тяжелый пакет

## TODO как появился tensorflow

## TODO где гонять модели? (Cloud functions, browser)

Итак у нас есть два сценария применения чудо-ml

1. У нас нет обученной модели. Тогда нам нужно ее обучить.
2. У нас уже загруженная моделька. Ее нужно погонять
3. У нас уже загруженная моделька, но нам ее надо доучить (transfer learning). Зачем это может быть нужно?
   Сценарий: у нас офигительно интерактивный процесс обучения. Мы не успеем все научить на сервере (например мы учим модельку с видео нашей камеры)

## Onnx js

## Всякие разные бекенды

Я покажу
